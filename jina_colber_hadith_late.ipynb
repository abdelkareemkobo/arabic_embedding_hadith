{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from qdrant_client import models as qmodels\n",
    "from qdrant_client import QdrantClient\n",
    "\n",
    "ds = load_dataset(\"arbml/Hadith\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = ds['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name jinaai/jina-colbert-v2.\n",
      "/home/linux/miniforge3/envs/kobo/lib/python3.11/site-packages/flash_attn/ops/triton/layer_norm.py:984: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "/home/linux/miniforge3/envs/kobo/lib/python3.11/site-packages/flash_attn/ops/triton/layer_norm.py:1043: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "Loaded the ColBERT model from Stanford NLP.\n",
      "The tokenizer does not support resizing the token embeddings, the prefixes token have not been added to vocabulary.\n"
     ]
    }
   ],
   "source": [
    "from pylate import indexes, models, retrieve\n",
    "\n",
    "embedding_model = models.ColBERT(\n",
    "    model_name_or_path=\"jinaai/jina-colbert-v2\",trust_remote_code=True,device='cuda',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68cfe05469e64e378e4b60abe431bcd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding queries (bs=64):   0%|          | 0/1943 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "descriptions_embeddings = list(\n",
    "    embedding_model.encode(documents['Text'],batch_size=64,show_progress_bar=True,device=\"cuda\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 128)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptions_embeddings[10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient,models as qmodels\n",
    "\n",
    "qdrant_client = QdrantClient(url=\"http://localhost:6333\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qdrant_client.create_collection(\n",
    "    collection_name=\"try\",\n",
    "    vectors_config=qmodels.VectorParams(\n",
    "        size=128,\n",
    "        distance=qmodels.Distance.COSINE,\n",
    "        multivector_config=qmodels.MultiVectorConfig(\n",
    "            comparator=qmodels.MultiVectorComparator.MAX_SIM #similarity metric between multivectors (matrices)\n",
    "        ),\n",
    "    ),\n",
    "    # quantization_config=qmodels.ScalarQuantization(\n",
    "    #     scalar=qmodels.ScalarQuantizationConfig(\n",
    "    #         type=qmodels.ScalarType.INT8,\n",
    "    #         quantile=0.99,\n",
    "    #         always_ram=True,\n",
    "    #     ),\n",
    "    # ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'أخبرنا قتيبة بن سعيد قال حدثنا سفيان عن الزهري عن أبي سلمة عن أبي هريرة أن النبي صلى الله عليه وسلم قال إذا استيقظ أحدكم من نومه فلا يغمس يده في وضوئه حتى يغسلها ثلاثا فإن أحدكم لا يدري أين باتت يده.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0][\"Text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_client.upload_points(\n",
    "    collection_name=\"try\",\n",
    "    points = [\n",
    "        qmodels.PointStruct(\n",
    "            id=idx,\n",
    "            vector=vector\n",
    "        )\n",
    "        for idx,vector in enumerate(descriptions_embeddings)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_1 = \"حديث جبريل الطويل عن الاسلام\"\n",
    "f_2 = \"هل يجوز زيارة القبور؟\"\n",
    "f_3 = \"أحاديث عن الصدقة\"\n",
    "f_4 = \"هل يوجب المذي الغسل؟\"\n",
    "\n",
    "f_5 = \"ماهي صفات المسلم؟\"\n",
    "h_1_t = \"من ترك صلاة مكتوبة متعمدا برئت منه ذمة الله\"  # 40165\n",
    "h_2_t = \"من سن في الإسلام سنة حسنة\"  # 37492\n",
    "h_3_t = \"الراحمون يرحمهم الرحمن\"  # 25311\n",
    "h_4_t = \"مثل المؤنين في توادهم وتراحمهم كمثل الجسد الواحد\"  # 36753\n",
    "h_5_t = \"ألا إن في الجسد مضغة إذا صلحت صلح الجسد كله\"  # 81731\n",
    "h_6_t = \"إن العبد ليتكلم بالكلمة من سخط الله\"  # 27672\n",
    "h_7_t = \"من تشبه بقوم فهو منهم\"  # 23973\n",
    "h_8_t = \"اجتنبوا أم الخبائث\"  # 5573\n",
    "h_9_t = \"ليس المؤمن باللعان و لا الطعان ولا الفاحش\"  # 22751\n",
    "\n",
    "h_10_t = \"فضل العالم علي العابد كفضل القمر\"  # 39828\n",
    "h_1 = \"العهد الذي  بيننا وبينهم الصلاة فمن تركها فقد كفر\"  # 78826\n",
    "h_2 = \"من دعا الي الهدي كان له من الأجور مثل أجور متبعه\"  # 27900\n",
    "h_3 = \"من لا يرحم الناس لا يرحمه الله\"  # 30040\n",
    "h_4 = \"المؤمن للمؤمن كالبنيان يشد بعضه بعضا\"  # 37904\n",
    "h_5 = \"إن الله لا ينظر الي صوركم و لكن ينظرالي قلوبكم\"  # 29642\n",
    "h_6 = \"من كان يؤمن بالله واليوم الأخر فليقل خيرا أو ليصمت\"  # 25437\n",
    "h_7 = \"يحشر المرء مع من يحب\"  #\n",
    "h_8 = \"لعن الله الخمر وشاربه وساقيها\"  # 24563\n",
    "h_9 = \"سباب المسلم فسوق وقتاله كفر\"  # 4037\n",
    "h_10 = \"من سلك طريقا يلتمس فيه علما\"  # 27070"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Text': 'أخبرنا قتيبة بن سعيد قال حدثنا سفيان عن الزهري عن أبي سلمة عن أبي هريرة أن النبي صلى الله عليه وسلم قال إذا استيقظ أحدكم من نومه فلا يغمس يده في وضوئه حتى يغسلها ثلاثا فإن أحدكم لا يدري أين باتت يده.'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hadith {'Text': 'حدثنا عبد الوهاب الخفاف قال سئل سعيد عن الرجل يتبع جنازة ما له من الأجر فأخبرنا عن قتادة عن سالم بن أبي الجعد عن معدان بن أبي طلحة عن ثوبان مولى رسول الله صلى الله عليه وسلم أن النبي صلى الله عليه وسلم قال من صلى على جنازة فله قيراط فإن شهد دفنها فله قيراطان فسئل النبي صلى الله عليه وسلم عن ذلك القيراط فقال مثل أحد.'}\n",
      "Hadith {'Text': 'و حدثني عن مالك عن ابن شهاب أنه قال من أهدى بدنة جزاء أو نذرا أو هدي تمتع فأصيبت في الطريق فعليه البدل.'}\n",
      "Hadith {'Text': 'حدثنا أبو النعمان حدثنا أبو عوانة عن مغيرة عن إبراهيم قال في رجل أوصى بمثل نصيب بعض الورثة قال لا يجوز وإن كان أقل من الثلث قال أبو محمد هو حسن.'}\n",
      "Hadith {'Text': 'و حدثني عن مالك عن يزيد بن خصيفة أنه سأل سليمان بن يسار عن رجل له مال وعليه دين مثله أعليه زكاة فقال لا.'}\n",
      "Hadith {'Text': 'حدثنا عثمان بن أبي شيبة حدثنا جرير عن منصور عن أبي وائل قال قال عبد الله من حلف على يمين يستحق بها مالا لقي الله وهو عليه غضبان ثم أنزل الله تصديق ذلك { إن الذين يشترون بعهد الله وأيمانهم إلى عذاب أليم } ثم إن الأشعث بن قيس خرج إلينا فقال ما يحدثكم أبو عبد الرحمن فحدثناه بما قال فقال صدق لفي أنزلت كان بيني وبين رجل خصومة في شيء فاختصمنا إلى رسول الله صلى الله عليه وسلم فقال شاهداك أو يمينه فقلت له إنه إذا يحلف ولا يبالي فقال النبي صلى الله عليه وسلم من حلف على يمين يستحق بها مالا وهو فيها فاجر لقي الله عز وجل وهو عليه غضبان فأنزل الله تصديق ذلك ثم اقترأ هذه الآية.'}\n",
      "Hadith {'Text': 'حدثنا عبد الله بن نمير حدثنا رزين الجهني حدثني أبو الرقاد قال خرجت مع مولاي وأنا غلام فدفعت إلى حذيفة وهو يقول إن كان الرجل ليتكلم بالكلمة على عهد رسول الله صلى الله عليه وسلم فيصير منافقا وإني لأسمعها من أحدكم في المقعد الواحد أربع مرات لتأمرن بالمعروف ولتنهون عن المنكر ولتحاضن على الخير أو ليسحتنكم الله جميعا بعذاب أو ليؤمرن عليكم شراركم ثم يدعو خياركم فلا يستجاب لكم.'}\n",
      "Hadith {'Text': 'أخبرنا محمد بن يوسف حدثنا سفيان عن أبي حرة عن إبراهيم { ومن يؤت الحكمة فقد أوتي خيرا كثيرا } قال الفهم بالقرآن.'}\n",
      "Hadith {'Text': 'حدثنا محمد بن عيينة عن علي بن مسهر عن إسمعيل عن الحسن قال الكفن من وسط المال يكفن على قدر ما كان يلبس في حياته ثم يخرج الدين ثم الثلث.'}\n",
      "Hadith {'Text': 'حدثنا روح حدثنا ابن جريج عن سليمان بن موسى عن نافع عن ابن عمر أن رسول الله صلى الله عليه وسلم قال الولاء لمن أعتق.'}\n",
      "Hadith {'Text': 'حدثنا هشيم أخبرنا علي بن زيد حدثنا الحسن قال وأخبرني رجل من بني سليط قال دفعت إلى رسول الله صلى الله عليه وسلم فسمعته يقول المسلم أخو المسلم لا يظلمه ولا يخذله التقوى هاهنا التقوى هاهنا مرتين أو ثلاثا وأشار بيده إلى صدره.'}\n"
     ]
    }
   ],
   "source": [
    "response = qdrant_client.query_points(\n",
    "    collection_name=\"try\",\n",
    "    query=list(embedding_model.encode(h_2))[0], #converting generator object into numpy.ndarray\n",
    "    limit=10, #How many closest to the query movies we would like to get\n",
    "    #with_vectors=True, #If this option is used, vectors will also be returned\n",
    "    with_payload=False#So metadata is provided in the output\n",
    ")\n",
    "\n",
    "for point in response.points:\n",
    "    point_id = point.id\n",
    "    score = point.score\n",
    "\n",
    "\n",
    "    # Print or process each value\n",
    "    # print(f\"ID: {point_id}, Score: {score}\")\n",
    "    print(f\"Hadith {documents[point_id]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Text': 'قال وكان يأتينا إذا قمنا إلى الصلاة فيمسح عواتقنا أو صدورنا وكان يقول لا تختلفوا فتختلف قلوبكم وكان يقول إن الله وملائكته يصلون على الصف الأول أو الصفوف الأول.'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[36890]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vectors;  {None}\n"
     ]
    }
   ],
   "source": [
    "collection_info = qdrant_client.get_collection(collection_name=\"try\")\n",
    "print(f\"Number of vectors; \",{collection_info.vectors_count})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "memory_size = number_of_vectors * vector_dimension * 4 bytes * 1.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08893346786499023"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = len(documents)*128*4*1.5\n",
    "x/1024/1024/1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.7220458984375"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_size = 1000000 * 1024 * 4  * 1.5 \n",
    "memory_size/1024/1024/1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kobo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
